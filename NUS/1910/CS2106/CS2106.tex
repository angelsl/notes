\documentclass[fontsize=9pt,twoside]{slnotes}
\usepackage{wrapfig}

\geometry{outer=0.5\columnsep}

\newfontfamily{\symbolfont}{DejaVu Sans}[Scale=MatchLowercase]
\DeclareTextFontCommand{\textsymbol}{\symbolfont}

\newcommand\benefits{\checkmark}
\newcommand\problems{\textsymbol{âœ—}}

\newcommand\sltilde{\char`~}
\begin{document}
\chapter{CS2106: Basic ideas}
The first computers did not have OSes. Rudimentary OSes like batch OSes that executed programs one at a time developed in the 1960s. Time-sharing OSes came in the 1970s.

OSes abstract away hardware, manage resources, control program execution and provide security and protection.

\sldef{Monolithic kernels} are kernels where the entire kernel runs in kernel mode. This design is well understood and tends to have better performance, but components tend to be more coupled and usually have complicated internal structures. Most Unices are largely monolithic.

\sldef{Microkernels} are kernels where the kernel is very small and handles only basic services like IPC, interrupt handling, and memory and task management. Higher level services run in user space, built on top of the basic facilities. This usually leads to a more robust kernel with better isolation, but performance tends to be lower.

\sldef{Layered systems} are generalisations of monolithic kernels that could be seen as a cross between microkernels and monolithic kernels: most services still run in kernel mode, but they are divided into layers, with the lowest being the hardware abstraction layer, and higher layers making use of lower layers. NT is generally seen as a layered system.

The \sldef{client-server model} is a variation of a microkernel. Servers are built on top of the microkernel and client processes request services from servers. Client and server processes can be on separate machines.

\sldef{Virtualisation} is used to run multiple OSes on the same hardware, or to debug an OS. Using a \sldef{hypervisor}, underlying hardware is virtualised. A \sldef{type 1} \sltilde{} is one that runs directly on hardware; a \sldef{type 2} \sltilde{} runs on a host OS.

\chapter{Processes}
A \sldef{process}/task/job is an abstraction to represent a program in execution.

Each \sltilde{} is represented in the system process table by a \sldef{process control block} which contains the register state (PC, SP, FP, GPRs, etc.), memory region information, PID, process state, etc.

CS2106 models processes as having 5 states: new, ready, running, blocked, and terminated.

\begin{wrapfigure}{l}{0.5\columnwidth}
\includegraphics[width=0.5\columnwidth]{pstates.pdf}
\end{wrapfigure}

A \sldef{syscall} is a request by a program for the system to do something. A change from user to kernel mode needs to happen. The general mechanism is \begin{slinenum}
\item program calls library
\item library performs syscall convention e.g. syscall no. in register, then execute special instruction
\item syscall entry dispatches to correct handler
\item syscall is executed
\item returns to user mode
\item library returns
\end{slinenum}.

An \sldef{exception} is a synchronous event caused by program execution e.g. arithmetic errors or segmentation faults; an exception handler (in the kernel) is executed. An \sldef{interrupt} is an external event e.g. timers or mouse/keyboard events; they are asynchronous and occur independently of program execution; program execution is suspended and an interrupt handler is executed.

Each task has a \sldef{stack} that keeps track of e.g. return address, function arguments, local variables, saved registers (register spilling when GPRs are exhausted).

A \sldef{calling convention} determines what the caller and callee does to set up the stack frame, how to pass arguments, what registers are saved by who, etc.

\section{Unix process abstraction}
\texttt{int fork()} creates a child process by duplicating the current process. Linux has \texttt{clone()} that allows more fine-grained control.

The \texttt{exec} family replaces the currently running program with a new one.

\texttt{void \_exit(int status)} ends the current process with the given status.

\texttt{pid\_t wait(int *wstatus)} waits for a child process to terminate; \texttt{pid\_t waitpid(pid\_t pid, int *wstatus, int options)} waits for (possibly) a specific child process; \texttt{waitid} waits for any child to change status.

When a process exits, it becomes a zombie process until its parent \texttt{wait()}s on it. If a process exits before child processes exit, the children will be inherited by \texttt{init}.

Linux process states: ready, running, stopped, suspended/sleeping, zombie.

\chapter{Scheduling}
\sldef{Concurrency} could be virtual i.e. pseudoparallelism, or physical: multi- or multicore CPUs. CS2106 does not really distinguish.

\sldef{Scheduling problem}: if there are more ready processes than CPUs, which should run?

3 categories of processing environments: batch i.e. no user so no need to be responsive, interactive/multiprogramming i.e. with user interaction so should be responsive, and realtime i.e. have hard deadline.

All \sltilde{} should have \begin{slinenum}
\item fairness i.e. each process/user gets a fair share of CPU and no starvation
\item balance i.e. all parts of the system should be used
\end{slinenum}

Two types of multitasking: \begin{slinenum}
\item \sldef{cooperative/non-preemptive}: processes run until blocked or voluntarily yield
\item \sldef{preemptive}: processes have fixed time quota (still can block or yield) and are scheduled out when quota is used
\end{slinenum}.

Process scheduling: \begin{slinenumthen}
\item scheduler triggered
\item context switch occurs if needed
\item scheduling algorithm picks process to run
\item process's context is set up
\item process runs
\end{slinenumthen}

\section{Batch processing scheduling}
Criteria: \begin{slinenum}
\item turnaround time: total time from submission to completion
\item throughput: rate of task completion
\item CPU utilitisation: \% of time CPU is working on a task
\end{slinenum}.

\sldef{FCFS}: arriving tasks are enqueued in a simple FIFO queue, and the head of the queue is run until done/block/yield. Guaranteed to have no starvation. \problems: convoy effect: if task A is CPU-bound and followed by a number of IO-bound tasks X, then while A is running Xs are waiting (IO idle) and when A is blocked on IO, Xs all run and then get blocked waiting for IO (CPU idle).

\sldef{Shortest job first}: select task with smallest total CPU time. Need to know total CPU time in advance, or guess. This minimises average waiting time, but starvation is possible; a long job may never be scheduled.

A common approach to predicting is an exponential average: \(P_{n+1} = \alpha A_n + (1-\alpha) P_n\), where \(\alpha\) is the weight placed on recent events.

\sldef{Shortest remaining time}: variant of SJF, using the shortest remaining time instead. It is preemptive: a new job with a shorter remaining time can preempt a currently running task.

\section{Interactive scheduling}
Criteria: \begin{slinenum}
\item response time: time between request and response
\item predictability: minimise variation in response time
\end{slinenum}.

To ensure good response time, preemptive scheduling algorithms are used. In order to preempt, the scheduler needs to run periodically, using a timer interrupt and a handler that invokes the scheduler.

The \sldef{interval of timer interrupt} (ITI) is the interval between timer interrupts. The \sldef{time quantum} is the execution duration given to a process, which must be multiples of the ITI, and could be constant or variable among processes.

\sldef{Round-robin}: tasks stored in FIFO queue, and run until TQ/yield/block. Response time bounded by \((n-1)q\) where \(q\) is TQ. Choice of TQ is important: high has lower overhead but longer waiting time, and v.v.

\sldef{Priority}: Select task with highest priority. Can be preemptive i.e. late high-prio task can preempt low-prio running task, or non-preemptive i.e. has to wait for next scheduling. \problems: low-prio task can starve; solutions: decrease prio of running task after each TQ, or don't consider current running task in next scheduling if TQ expires.

\sldef{Priority inversion}: If lower prio task preempts higher prio task e.g. high A, B, low C, C starts and locks file, B preempts C, A arrives and needs file but locked by C, so B runs even though A has higher prio.

\sldef{Multi-level feedback queue}: Adapts to process behaviour and minimises response (for IO-bound) and turnaround (for CPU-bound) time. Rules: if \(p(A) > p(B)\) then A runs; if \(p(A) == p(B)\) then A and B run in RR. New tasks start at highest prio; tasks that finish TQ drop prio, but if yield/block before TQ then keep prio. \problems: too many interactive tasks can cause long-running tasks to starve; can be gamed if tasks yield just before TQ; task that stops being CPU-bound stays at low prio. Solutions: periodic priority boost, and account overall time usage, and drop prio when that exceeds allotment.

\sldef{Lottery}: Give tickets to processes for resources, and choose tickets randomly when scheduling. It \begin{slinenum}
\item is responsive: new tasks can participate in the next lottery
\item provides good control: can vary tickets per task
\item is simple in implementation
\end{slinenum}.

\chapter{IPC}
\sldef{Shared memory}: communicate using a memory region mapped to multiple tasks. Advantages: efficient (OS only involved in initial steps) and easy to use. Disadvantages: synchronisation is hard because it is a shared resource.

POSIX shared memory: \begin{slinenum}
\item \texttt{int shmget(key, size, shmflg)} returns the ID of a new or existing shared memory segment (to create, \texttt{key = IPC\_PRIVATE}, \texttt{shmflg = IPC\_CREAT | <octal permissions>})
\item \texttt{void *shmat(shmid, shmaddr, shmflg)} attaches the specified SHM to \texttt{shmaddr} or a suitable address if null
\item \texttt{int shmdt(shmaddr)} detaches the SHM at the address
\item \texttt{int shmctl(shmid, cmd, ...)} destroys the SHM if \texttt{cmd} is \texttt{IPC\_RMID} (only for owner/creator)
\end{slinenum}.

\sldef{Message passing}: passing message via (usually) syscalls. Messages have to be stored in kernel memory, and each operation is a syscall. Naming: either direct or indirect i.e. via mailboxes or ports, which can be shared. Sync/async: sync means sender/receiver is blocked until message is received/sent; async means sender resumes immediately and receiver receives if available else \texttt{EAGAIN}. Advantages: portable and easier synchronisation. Disadvantages: inefficient and harder to use (messages limited in size/format).

\sldef{Unix pipes}: read and write ends; can be shared between processes; FIFO---bytes read in order. Functons as a circular bounded byte buffer with implicit synchronisation: writers wait when buffer is full, readers wait when buffer is empty. Variants: half-duplex like Linux, or full-duplex i.e. any end can read/write.

Unix pipes: \texttt{int pipe(int fd[])}, returns an array of read and write end FD. Also \texttt{dup}/\texttt{dup2}.

\sldef{Unix signals}: asynchronous notification regarding an event; recipient handles the signal with default handlers or user-supplied handler (only for some signals). Install handler with \texttt{signal} or \texttt{sigaction}.

\chapter{Threading}
Motivations: processes are expensive due to duplicate memory space and other context, and it is harder for independent processes to communicate (requiring IPC).

Threads share the same memory context (text, data, heap) and others (PID, FDs, etc.), but usually have a unique TID, and of course stack and registers.

Switching processes involves switching the OS, memory and hardware contexts; switching threads only requires a hardware context switch (registers and stack i.e. SP/FP).

\benefits: less resources to manage compared to multiprocess; resources shared so no need for IPC/etc.; can appear more responsive and take advantage of multiple CPUs.

\problems: parallel threads can call system calls simultaneously, so need to ensure correctness. \texttt{fork} will clone only the thread that called it (but that includes the entire memory space of the parent); \texttt{exit} (syscall) exits only the thread but libc calls \texttt{exit\_group} so ends all threads; \texttt{execve} destroys all threads.

Threads can be implemented as user threads or kernel threads.

\sldef{User threads}: advantages: doesn't require OS support, thread operations are just library calls, and can be more configurable and flexible; disadvantages: OS is unaware so scheduling is done at process level; if one thread is blocked the process is blocked; and cannot use multiple CPUs.

\sldef{Kernel threads}: advantages: kernel can schedule multiple threads so can use multiple CPUs; disadvantages: thread operations are now syscalls so slower; generally less flexible.

\sldef{Hybrid threads}: both user and kernel threads; user threads can bind to kernel threads. Very flexible.

Modern processors: simultaneous multithreading: allow threads to run natively and in parallel on the same core.

\texttt{int pthread\_create(pthread\_t *thread, pthread\_attr\_t *attr, void *(*start\_routine) (void *), void *arg)}

\texttt{void pthread\_exit(void *retval)}

\texttt{int pthread\_join(pthread\_t thread, void **retval)}.

\chapter{Synchronisation}
With parallelism, race conditions can happen due to unsynchronised read/write of a resource. Solution: designate given section of code as a \sldef{critical section} that only one process can enter at a time.

Properties of correct critical section impl.: \begin{slinenum}
\item mutual exclusion: if one process is in CS, all others cannot enter
\item progress: if no process is in CS, one waiting process should be granted access
\item bounded wait: after process P requests to enter CS, there must be an upper bound of the number of times another process can enter the CS before P
\item independence: a process not in CS should never block another process
\end{slinenum}.

Incorrect synchronisation can lead to: \begin{slinenumor}
\item \sldef{deadlock}: all processes blocked
\item \sldef{livelock}: processes keep changing state to avoid deadlock but make no meaningful progress
\item \sldef{starvation}: some processes are blocked forever
\end{slinenumor}.

Critical sections can be implemented in multiple ways.

\sldef{Test and set}: instruction that returns the value at a memory location, then sets it to 1 (both actions as one atomic action). To enter CS, test-and-set until value returned is 0. To exit, just set value to zero. Disadvantages: busy waiting.

\sldef{Peterson's algorithm}

\includegraphics[width=\columnwidth]{petersons.pdf}

Disadvantages: busy-waiting, low-level, and not general

\sldef{Semaphore}: high-level mechanism; provides a way to block some processes, and unblock some sleeping processes. A semaphore contains an integer value, and can be initialised with any non-negative values.

Two atomic operations: \begin{slinenum}
\item \sldef{wait}: decrement \(S\); if now \(S < 0\), blocks
\item \sldef{signal}: increments \(S\); wakes up one sleeping process if any; never blocks
\end{slinenum}.

Semaphore invariant: \(S_{\text{current}} = S_{\text{initial}} + \text{no. signal()s} - \text{no. wait()s}\)

A binary semaphore is limited to 0 or 1; a general semaphore (\(S \ge 0\) can be implemented by a binary semaphore.

\sldef{Conditional variable}: allow tasks to wait for an event to happen; another task can signal one waiting task, or broadcast to all waiting tasks. Note: different from semaphore as if no tasks are waiting, signalling has no effect. (A task that later waits will still block.)

\section{Synchronisation problems}
\sldef{Producer-consumer}: producer produces only when buffer is not full; consumer consumes only when buffer is not empty.

\sldef{Reader-writer}: readers can share, writers must have exclusive excess.

\sldef{Dining philosophers}: Tanenbaum solution: diners signal their left and right if they are waiting. Partial order solution: number chopsticks 1 to 5; always pick up lower-numbered chopstick.

pthread provides a mutex \texttt{pthread\_mutex} with \texttt{pthread\-\_\-mutex\-\_\-(un)lock()}, and a conditional variable \texttt{pthread\_cond} with \texttt{pthread\-\_\-cond\-\_\-\{wait\-,\-signal\-,\-broadcast\}()}.

\chapter{Memory}
\sldef{Memory hierarchy}: registers ~1 ns access; cache ~10 ns access; RAM ~100 ns; HDD ~10 ms.

\section{Abstractions}
\sldef{No memory abstraction}: memory access is straightforward, but there is no way to protect one process's memory from other processes, and if two processes access the same addresses, they will conflict.

\sldef{Relocation}: offset all references in a process. \problems: slow loading time; need to somehow identify memory addresses from other normal integers.

\sldef{Base and limit}: compile all memory references to be an offset from the base register. Check all accesses against the limit register. \problems: every access involves an addition and comparison.

\sldef{Logical address}: translated to physical address by hardware or OS.

\section{Contiguous memory management}
\sldef{Fixed partitioning}: divide physical memory into a fixed number of equal partitions. \benefits: easy to manage; fast allocation. \problems: partition size must be big enough to fit the largest process; smaller processes waste memory i.e. internal fragmentation.

\sldef{Dynamic partitioning}: partitions created based on the needs of each process. \benefits: flexible; removes internal fragmentation. \problems: need to maintain more information; need to locate appropriate region when allocation; tends to lead to a large number of holes with many processes created and terminated i.e. external fragmentation.

\sldef{Dynamic partitioning algorithm}: find a hole, then split the hole. To find a hole: \begin{slinenumor}
\item first-fit: find the first hole large enough
\item best-fit: find the smallest hole large enough
\item worst-fit: find the largest hole
\item buddy system
\end{slinenumor}.

\sldef{Buddy system}

\includegraphics[width=\columnwidth]{buddysystem.pdf}

\sldef{Storage}: an array of linked lists \texttt{A[0..=K]} where \(2^K\) is the largest block size, and \texttt{A[N]} tracks the address of free blocks of size \(2^N\). \sldef{Allocating} \(N\) bytes: find the smallest \(S\) s.t. \(2^S \ge N\). Access \texttt{A[S]}; if a free block exists, use that, else find the smallest \(R \in [S+1, K]\) s.t. \texttt{A[R]} has a free block, then split that block repeatedly to get a new free \(2^S\)-byte block. \sldef{Deallocating} a block B: check \texttt{A[S]} for B's buddy; if buddy is free, merge and repeatedly merge where buddies exist. Otherwise insert B to \texttt{A[S]}.

Two blocks are size \(2^S\) buddies if their address's \(S\)th (0-based) bits are complements and the leading bits up to that bit are the same.

\section{Disjoint memory management}
\subsection{Paging}
Divide physical memory into \sldef{physical frames} of fixed size; logical memory split into \sldef{logical pages} of equal size; at runtime, pages are loaded into any available logical frames.  \sldef{Implementation}: \sldef{page table} to map logical addresses to physical. Optimise this by keeping page size a power of 2; then the page/frame number is just the most significant bits of the address.

\benefits: logical memory remains contiguous, but occupied physical memory can be discontinuous. No more external fragmentation: all free frames can be used. \problems: Internal fragmentation: logical memory space may not be a multiple of page size.

Paging can be done in pure software, with a page table stored with the process information. \problems: two accesses required for every memory reference: one to get the frame number, one for the actual memory access.

Modern processors provide a \sldef{translation lookaside buffer} which optimises this. On context switch, the TLB is flushed. The average memory access time with TLB is \(P (T_t + T_m) + (1 - P) (T_t + 2T_m)\) where \(P\) is the TLB-hit rate, \(T_t\) is the TLB access time, and \(T_m\) is the memory access time, ignoring the TLB insertion time and CPU caching.

Paging can be extended to provide memory protection with access rights (R/W/X) (e.g. for shared R/X code frames) and page validity (to check for out-of-bounds access), attached to each page table entry.

\subsection{Segmentation}
Separate memory into separate segments with a name and a limit. All memory references must be specified as a segment and offset.

Each segment is mapped to a contiguous physical memory region with a base address and a limit, and the logical address is the pair of segment and offset.

\benefits: Each segment is independent and contiguous, so they can be resized and protected independently. \problems: Needs variable-size contiguous memory regions, so it can lead to external fragmentation.

\sldef{Segmentation with paging}: each segment is now composed of pages instead of one contiguous region. A segment can grow by allocating a new page to the segment.

\section{Virtual memory}
...allows processes' logical memory to exceed the size of physical memory. This can be done by extending paging: now, some pages can be "paged out" to secondary storage.

When a page is accessed, the OS needs to check if the page is in memory, and if not (\sldef{page fault}), load the page into memory.

Virtual memory exploits the locality principle. Temporal: after a page is loaded, it is likely to be accessed again. Spatial: a page contains contiguous locations likely to be accessed again.

\section{Page table structures}
Note: each process must have its own page table!

\sldef{Direct paging}: just have all entries in a single table, for each process. \problems: waste of space since most processes do not use the full range of virtual memory.

\sldef{2/multi-level paging}: split the page table into regions; regions are allocated as needed. Need a "region table" to track regions; regions can also be identified by bit-prefixes, like pages. \benefits: less overhead. \problems: more indirection.

\sldef{Inverted page table}: map frame number to process and page number. \benefits: only one table for all processes. \problems: very slow translation.

\section{Page replacement algorithms}
If there is no free frame during a page fault, a page needs to be evicted.

\sldef{Local and global replacement}: if only a page owned by the page fault-causing process can be evicted, it is \sldef{local replacement}. \benefits: frames allocated to a process are constant, but any thrashing is contained to one process; \problems: need to decide how many frames to allocate; bad decision will cause the process to thrash.

If any page can be evicted, it is \sldef{global replacement}. \benefits: processes that need more frames can get it from other processes; \problems: badly-behaving processes hinder others, possibly causing other processes to thrash.

A good algorithm will minimise the number of page faults. The best algorithm replaces the page that will not be used again for the longest time; but this is impossible because future knowledge of memory references is needed. We use this as a basis of comparison.

\sldef{FIFO}: evict the oldest page; can be implemented using a queue. \problems: Belady's anomaly: more pages leads to more page faults, because FIFO does not exploit temporal locality.

\sldef{Least recently used} (LRU): makes use of temporal locality; replace the page that has not been used for the longest. \benefits: good results generally. \problems: hard to implement; need to keep track of last use. Can use a counter, but then to evict all pages need to be checked to find the oldest, and the counter can overflow. Can use a stack, but it is not a pure stack: entries can be removed from anywhere in the stack.

\sldef{Second-chance} (CLOCK): modified FIFO: have a "referenced bit" in each PTE, and a "next victim" pointer in a circular queue. When a page is referenced, set the bit; when a page is to be evicted, if the next victim's bit is set, unset and advance, and repeat; else evict that page.

\sldef{Working set model}: a model to determine the number of frames to allocate to a process. \(W(t, D)\) denotes the set of pages referenced in the past \(D\) time units from \(t\). By allocating just enough frames for the pages in \(W\), we reduce page faults.

\chapter{Filesystems}
Filesystems provide an abstraction over physical media, and also protection and sharing between processes and users. They need to be self-contained, persistent and efficient.

Filesystems provide \sldef{files}, which have metadata including an ID (for the FS), a name, type, size, access control, time, etc. File data can be either just an array of bytes (Unix view), or fixed or variable length records. Files can be accessed sequentially, randomly or directly (e.g. mmap?).

Filesystems also provide \sldef{directories} which provide a logical grouping of files. Directories can be single-level (i.e. cannot contain subdirs), trees (single-level + subdirs), DAGs (trees + hard links), or general graphs (DAGs + symlinks).

File operations are done using system calls in Unix. Open files are tracked with a system-wide file descriptor table, and a per-process file descriptor table has pointers to file descriptors in the system-wide table.

\section{Filesystem implementation}
Disks can be treated generally as an array of logical blocks (~512 to 4096 bytes). Logical blocks are mapped to disk sectors, usually by the hardware.

Filesystems usually contain some sort of boot information, partition metadata, directory data and file data.

\subsection{File abstraction}
Implementations of the file abstraction must allow efficient access while reducing wasted space and fragmentation.

\sldef{Contiguous block allocation}: allocate consecutive blocks to a file; each file entry is the starting block and length. \benefits: simple; fast access. \problems: external fragmentation; entire file size needs to be allocated in advance.

\sldef{Linked list}: have each block store the next block pointer along the file data; each file entry is just the first (and last, possibly) block number. \benefits: solve external fragmentation. \problems: slow random seek; part of disk block used for pointer; less reliable (an error in one pointer will destroy entire file).

\sldef{FAT linked list}: move all block pointers into a single table; keep the table in memory. \benefits: faster random access. \problems: the FAT tracks all disk blocks; can be large when disk is large, consuming a lot of memory.

\sldef{Indexed allocation}: each file has an index block which is an array of block addresses. \texttt{Index\-Block[N]} gives the address of the \(N\)th block of the file. \benefits: less memory overhead and fast random access; \problems: file size limited by index block size; index block overhead.

Variations on indexed allocation: linked list index blocks to allow larger file size---each index block points to the next block; or multi-level index, a similar idea to multi-level paging.

\subsection{Free space management}
To allocate blocks for files, we need to know which disk blocks are free.

\sldef{Bitmap}: each block is represented by 1 bit. \benefits: can find first free block or blocks easily by bit-level operations. \problems: need to keep bitmap in memory for efficiency.

\sldef{Linked list}: use a linked list of free blocks. \benefits: easy to locate free blcok; only first pointer needed in memory. \problems: high overhead, but can be mitigated by storing the free block list in free blocks.

\subsection{Directory abstraction}
The directory needs to keep track of contained files, and usually, map filenames to files as well.

\sldef{List}: \problems: linear search to find a file; can be somewhat mitigated by using a cache to remember a few recent searches.

\sldef{Hashtable}: \benefits: faster lookup. \problems: hashtable has limited size; needs good hash function.

\sldef{File metadata}: Either store everything in the directory entry, or just the filename, pointing to an auxilliary structure for the rest of the metadata.

\subsection{Scheduling}
Scheduling helps to mitigate seek time and fairly share I/O between processes.

Some algorithms incldue: FCFS, shortest seek first, SCAN (bi-directional) and C-SCAN (single direction, usually out to in), deadline (3 queues: sorted, read FIFO, write FIFO), no-op, completely fair queueing (time slice and per-process sorted queues), and budget fair queueing (fair sharing based on the number of sectors requested).

\section{Filesystem case studies}
\subsection{FAT}
File data is allocated to data block clusters. Allocation information is kept as a linked list.

The FAT has one entry per cluster; it stores cluster information: free, EOF, bad, or the cluster number of the next cluster. Free space is not tracked and must be calculated from the FAT.

A directory is a special file, with each entry being fixed at 32-bytes, containing the 8.3 file name, attributes, creation time, size, and first cluster. The first byte of the name may have special meanings: deleted (\texttt{0xE5}), end-of-directory, parent directory, etc. The creation time is limited to 1980 to 2107, and has 2-second resolution.

The number in FAT12/16/32 indicates the number of bits in the cluster index, and therefore the maximum number of clusters. (FAT32 uses only 28 bits.) (Special values like EOF and FREE also reduce the number of valid cluster indices.)

Larger cluster size \benefits: larger partition possible; \problems: larger internal fragmentation.

Long filenames are implemented using entries in directories before the actual entry of the file. For backwards compatibility, LFN entries have invalid attributes so implementations that do not support LFN will ignore LFN entries.

To delete a file: set the first letter in the filename to \texttt{0xE5}; mark FAT entries as free.

\subsection{ext2}
Disk space is split into blocks, corresponding to one or more disk sectors, and blocks are grouped into \sldef{block groups}. Each file and directory is denoted by an \sldef{inode}, containing file metadata and data block addresses.

Each block group contains a \sldef{superblock} describing the FS (total inodes, inodes per group, total blocks, blocks per group, etc. The superblock is duplicated in each block group.

Each block group also has a \sldef{group descriptor} describing each block group (number of free blocks, inodes, and location of bitmaps). Each block group contains a copy of all group descriptors after its superblock copy.

Each block group also has a block bitmap, tracking block usage in the block group; an inode bitmap, tracking inode usage in the group; and an inode table of inodes in the group, which is just an array of inodes.

The inode (128 bytes) contains the file's mode (2), uid (2), gid (2), size (4/8), a/m/ctime (4 ea), 15 data block pointers (4 ea), and refcount (2). The 15 pointers consist of 12 direct pointers to blocks, 1 pointer to a single indirect block, 1 pointer to a double indirect block, and 1 pointer to a triple indirect block. \benefits: fast access to small files with flexibility in handling large files.

A directory is a special file, containing a list of directory entries containing the file's inode number, dentry size, filename size, file type (file, directory, etc), and filename.

To delete a file: remove the dentry, updating the previous entry to point to the next entry (end); update the inode and block bitmap.

Directory permissions: read: can read dentries; write: can modify dentries; execute: can use as working directory.
\end{document}
